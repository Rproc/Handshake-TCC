{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.util import utils as u\n",
    "from source import metrics, plots\n",
    "from source import scargc, hs\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import resource\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolsize = 150\n",
    "clusters = 2\n",
    "n_components = 2\n",
    "step = 10\n",
    "\n",
    "# base = '/home/localuser/Documentos/procopio/ccomp/tcc/datasets/'\n",
    "base = '/home/test/Documentos/Handshake-TCC/datasets/'\n",
    "\n",
    "#   list = ['1CSurr.txt', '2CDT.txt', '2CHT.txt']# 'NOAA.txt', 'elec.txt', 'keystroke.txt']\n",
    "# list = ['keystroke.txt']\n",
    "list = ['spam_corpus.txt']\n",
    "\n",
    "\n",
    "array_ep = [0.15]#, 0.10, 0.15]\n",
    "array_p = [20]#,20, 30]\n",
    "k = 5\n",
    "\n",
    "adr = base + list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset, data_labeled, dataset_train, l_train, stream, l_stream, n_features = u.criar_datasets(5, adr, 0)\n",
    "\n",
    "# print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "predicted, updt, clustering = hs.handshakePCA(dataset, data_labeled, dataset_train, l_train, stream, l_stream, n_components, n_features, array_ep[0], array_p[0], k, 1)\n",
    "# predicted, updt = scargc.newScargc(dataset, data_labeled, dataset_train, l_train, stream, l_stream, poolsize, clusters, n_features, k)\n",
    "\n",
    "# predictedHS, updt, clustering = hs.handshakePCA(dataset, data_labeled, dataset_train, l_train, stream, l_stream, n_components, n_features, array_ep[0], array_p[0], k)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/metrics/classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tempo = end - start\n",
    "\n",
    "acc_percent, f1_percent, mcc_percent = metrics.makeBatches(l_stream, predicted, len(stream), step)\n",
    "score, f1, mcc, std = metrics.metrics(acc_percent, l_stream, predicted, step, f1_type = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  0.2177537899123143\n",
      "Macro-F1:  0.1789872447020602\n",
      "MCC:  0.005606444287352238\n",
      "Desvio Padrão:  0.15468896295492343\n",
      "Numero de atualizações:  1354\n",
      "Tempo:  1566.514776468277\n"
     ]
    }
   ],
   "source": [
    "# print('memory peak: ', mem)\n",
    "print('Acc: ', score)\n",
    "print('Macro-F1: ', f1)\n",
    "print('MCC: ', mcc)\n",
    "print('Desvio Padrão: ', std)\n",
    "print('Numero de atualizações: ', updt)\n",
    "print('Tempo: ', tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plots.plotPerBatches(stream, predicted, l_stream, len(stream), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "predicted, updt, clustering = hs.handshake2(dataset, data_labeled, dataset_train, l_train, stream, l_stream, n_components, n_features, array_ep[0], array_p[0], k)\n",
    "# predicted, updt = scargc.newScargc(dataset, data_labeled, dataset_train, l_train, stream, l_stream, poolsize, clusters, n_features, k)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "tempo = end - start\n",
    "\n",
    "acc_percent, f1_percent, mcc_percent = metrics.makeBatches(l_stream, predicted, len(stream), step)\n",
    "score, f1, mcc, std = metrics.metrics(acc_percent, l_stream, predicted, step, f1_type = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('memory peak: ', mem)\n",
    "print('Acc: ', score)\n",
    "print('Macro-F1: ', f1)\n",
    "print('MCC: ', mcc)\n",
    "print('Desvio Padrão: ', std)\n",
    "print('Numero de atualizações: ', updt)\n",
    "print('Tempo: ', tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
